Intro to AI 1 Artificial Intelligence: Adversarial Search 2 Motivation GO chess tic-tac-toe 3 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic Games ◼ Where we are today 5 Adversarial Search ◼ Classical application for heuristic search ❑ simple games: exhaustively searchable ❑ complex games: only partial search possible ❑ additional problem: playing against opponent ◼ Here, we look at 2-player adversarial games ❑ win, lose, or tie 6 Types of Games ◼ Perfect Information ❑ A game with the perfect information is that in which agents can look into the complete board. Agents have all the information about the game, and they can see each other moves also. ❑ Examples: Chess, Checkers, Go, etc. ◼ Imperfect Information ❑ Game state only partially observable, choices by opponent are not visible (hidden) ❑ Example: Battleship, Stratego, many card games, etc. 7 Types of Games (II) ◼ Deterministic games ❑ No games of chance (e.g., rolling dice) ❑ Examples: Chess, Tic-Tac-Toe, Go, etc. ◼ Non-deterministic games ❑ Games with unpredictable (random) events (involving chance or luck) ❑ Example: Backgammon, Monopoly, Poker, etc. 8 Types of Games (III) ◼ Zero-Sum Game ❑ If the total gains of one player are added up, and the total losses are subtracted, they will sum to zero (example: cutting a cake) ❑ A gain by one player must be matched by a loss by the other player ❑ One player tries to maximize a single value, the other player tries to minimize it ❑ Examples: Checkers, Chess, etc. ◼ Non-Zero-Sum Game ❑ Win-Win or Lose-Lose type games ❑ Famous example: The Prisoner’s Dilemma https://en.wikipedia.org/wiki/Prisoner%27s_dilemma https://en.wikipedia.org/wiki/Prisoner%27s_dilemma 9 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic games ◼ Where we are today 10 Example: Game of Nim ◼ Rules ❑ 2 players start with a pile of tokens ❑ move: split (any) existing pile into two non-empty differently-sized piles ❑ game ends when no pile can be unevenly split ❑ player who cannot make his move loses 11 State Space of Game Nim ◼ start with one pile of tokens ◼ each step has to divide one pile of tokens into 2 non-empty piles of different size ◼ player without a move left loses game source: G. Luger (2005) 12 MiniMax Search ◼ Game between two opponents, MIN and MAX ❑ MAX tries to win, and ❑ MIN tries to minimize MAX’s score ◼ Existing heuristic search methods do not work ❑ would require a helpful opponent ❑ Need to incorporate “hostile” moves into search strategy 13 Exhaustive MiniMax Search ◼ For small games where exhaustive search is feasible ◼ Procedure: 1. build complete game tree 2. label each level according to player’s turn (MAX or MIN) 3. label leaves with a utility function to determine the outcome of the game ◼ e.g., (0, 1) or (-1, 0, 1) 4. propagate this value up: ◼ if parent=MAX, give it max value of children ◼ if parent=MIN, give it min value of children 5. Select best next move for player at root as the move leading to the child with the highest value (for MAX) or lowest values (for MIN) 14 Exhaustive MiniMax for Nim Bold lines indicate forced win for MAX source: G. Luger (2005) 0: win for MIN 1: win for MAX 15 n-ply MiniMax with Heuristic ◼ Exhaustive search for interesting games is rarely feasible ◼ Search only to predefined level ❑ called n-ply look-ahead ❑ n is number of levels ◼ No exhaustive search ❑ nodes evaluated with heuristics and not win/loss ❑ indicates best state that can be reached ❑ horizon effect ◼ Games with opponent ❑ simple strategy: try to maximize difference between players using a heuristic function e(n) Heuristic Function for 2-player games ◼ simple strategy: ❑try to maximize difference between MAX’s game and MIN’s game ◼ typically called e(n) ◼ e(n) is a heuristic that estimates how favorable a node n is for MAX ❑ e(n) > 0 --> n is favorable to MAX ❑ e(n) < 0 --> n is favorable to MIN ❑ e(n) = 0 --> n is neutral 16 Choosing a Heuristic Function e(n) 17 18 MiniMax with Fixed Ply Depth Leaf nodes show the actual heuristic value e(n) source: G. Luger (2005) 19 MiniMax with Fixed Ply Depth Leaf nodes show the actual heuristic value e(n) Internal nodes show back-up heuristic value source: G. Luger (2005) max(2,3) = 3 max(5,9) = 9 …. 20 MiniMax with Fixed Ply Depth Leaf nodes show the actual heuristic value e(n) Internal nodes show back-up heuristic value source: G. Luger (2005) min(3,9) = 3 min(0,7) = 9 min(2,6) = 2 21 MiniMax with Fixed Ply Depth Leaf nodes show the actual heuristic value e(n) Internal nodes show back-up heuristic value source: G. Luger (2005) max(3, 0, 2) = 3 22 MiniMax with Fixed Ply Depth Leaf nodes show the actual heuristic value e(n) Internal nodes show back-up heuristic value source: G. Luger (2005) Best next move Example: e(n) for Tic-Tac-Toe ◼ Possible e(n) number of rows, columns, and diagonals open for MAX - number of rows, columns, and diagonals open for MIN + , if n is a forced win for MAX - , if n is a forced win for MIN e(n) = 8-8 = 0 e(n) = 6-4 = 2 e(n) = 3-3 = 0 23 e(n) = 24 More examples… source: G. Luger (2005) 25 Two-ply MiniMax for Opening Move source: G. Luger (2005) Tic-Tac-Toe tree at horizon = 2 26 Two-ply MiniMax: MAX’s possible 2nd moves source: G. Luger (2005) 27 Two-ply minimax: MAX’s move at end source: G. Luger (2005) 28 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic games ◼ Where we are today 29 Alpha-Beta Pruning ◼ Optimization over MiniMax, that: ❑ ignores (cuts off, prunes) branches of the tree that cannot possibly lead to a better solution ❑ reduces branching factor ❑ allows deeper search with same effort 30 Alpha-Beta Pruning: Example 1 ◼ With MiniMax, we look at all possible nodes at the n-ply depth ◼ With α-β pruning, we ignore branches that could not possibly contribute to the final decision B will be >= 5 So we can ignore B’s right branch, because A must be 3 D will be <= 0 But C will be >= 3 So we can ignore D’s right branch E will be <= 2. So we can ignore E’s right branch Because C will be 3. source: G. Luger (2005) A=min(3, max(5,?)) C=max(3, min(0,?), min(2,?)) Alpha-Beta Pruning Algorithm 31 ◼ α : lower bound on the final backed-up value. ◼ β : upper bound on the final backed-up value. ◼ Alpha pruning: ❑ eg. if MAX node's α = 6, then the search can prune branches from a MIN descendant that has a β <= 6. ❑ if child β <= ancestor α → prune ❑ ◼ Beta pruning: ❑ eg. if a MIN node's β = 6, then the search can prune branches from a MAX descendant that has an α >= 6. ❑ if ancestor β <= child α → prune value ≥ 6 value ≤ 5 incompatible… so stop searching the right branch; the value cannot come from there! MAX MIN value ≤ 6 value ≥ 7 MIN MAX b=6 =-∞  =7 b=+∞ b=+∞ =6 b=5 =-∞ incompatible… so stop searching the right branch; the value cannot come from there! 32 Alpha-Beta Pruning Algorithm 01 function alphabeta(node, depth, α, β, maximizingPlayer) 02 if depth = 0 or node is a terminal node 03 return the heuristic value of node 04 if maximizingPlayer 05 v := -∞ 06 for each child of node 07 v := max(v, alphabeta(child, depth - 1, α, β, FALSE)) 08 α := max(α, v) 09 if β ≤ α 10 break (* β cut-off *) 11 return v 12 else 13 v := ∞ 14 for each child of node 15 v := min(v, alphabeta(child, depth - 1, α, β, TRUE)) 16 β := min(β, v) 17 if β ≤ α 18 break (* α cut-off *) 19 return v Initial call: alphabeta(origin, depth, -∞, +∞, TRUE) source: http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning Example with tic-tac-toe 33 min level max level source: robotics.stanford.edu/~latombe/cs121/2003/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Example with tic-tac-toe e(n) = 2 34 max level min level value ≤ 2 source: robotics.stanford.edu/~latombe/cs121/2003/home.htm b=2 =-∞ http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Example with tic-tac-toe e(n) = 1e(n) = 2 35 value ≤ 2 1 min level max level source: robotics.stanford.edu/~latombe/cs121/2003/home.htm b=2 1 =-∞ http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Example with tic-tac-toe value ≥ 1 e(n) = 1 value = 1 e(n) = 2 36 min level source: robotics.stanford.edu/~latombe/cs121/2003/home.htm max level b=+∞ =1 http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Example with tic-tac-toe value ≥ 1 e(n) = 1 value = 1 e(n) = 2 e(n) = -1 value ≤ -1 37 min level max level source: robotics.stanford.edu/~latombe/cs121/2003/home.htm b=+∞ =1 b=-1 =-∞ http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Example with tic-tac-toe e(n) = 1 b = 1 e(n) = 2 e(n) = -1 value ≤ -1 child β <= ancestor α → stop search 38 incompatible… so stop searching the right branch; the value cannot come from there! source: robotics.stanford.edu/~latombe/cs121/2003/home.htm b=+∞ =1 b=-1 =-∞ value ≥ 1 http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm http://robotics.stanford.edu/~latombe/cs121/winter02/home.htm Max ------------------------------------------------------------------------------------------------------- Min ------------------------------------------------------------------------------------------------------- Max ------------------------------------------------------------------------------------------------------- Min -------------------------------------------------------------------------------------------------------- 39 Alpha-Beta Pruning: Example 2 source: http://en.wikipedia.org/wiki/File:AB_pruning.svg ≤5 =5 =6 =5 ≥5 =7 ≤7 =4 ≤4 ≤4 =5 ≤5 =3 =3 =3 =3 ≥3 =6 =6 ≥6 =6 ≤6 ≤6 =6 ≤6 =7 =7 =7 =6 ≥6 =5 =5 =5 ≤5 =6 ✓ x x ✓ ✓ x 40 Alpha-Beta Pruning: Example 2 source: http://en.wikipedia.org/wiki/File:AB_pruning.svg Alpha-Beta Pruning: Example 3 41 Alpha-Beta Pruning: Example 3 42 Alpha-Beta Pruning: Example 3 43 <=4 Alpha-Beta Pruning: Example 3 44 <=3 Alpha-Beta Pruning: Example 3 45 <=3 Alpha-Beta Pruning: Example 3 46 =3 Alpha-Beta Pruning: Example 3 47 =3 >=3 Alpha-Beta Pruning: Example 3 48 =3 >=3 Alpha-Beta Pruning: Example 3 49 =3 >=3 <=2 Alpha-Beta Pruning: Example 3 50 =3 >=3 <=2 prune Alpha-Beta Pruning: Example 3 51 =3 =3 Alpha-Beta Pruning: Example 3 52 =3 =3 <=3 Alpha-Beta Pruning: Example 3 53 =3 =3 <=4 <=3 Alpha-Beta Pruning: Example 3 54 =3 =3 <=2 <=3 Alpha-Beta Pruning: Example 3 55 =3 =3 =2 <=3 Alpha-Beta Pruning: Example 3 56 =3 =3 =2 =2 <=3 Alpha-Beta Pruning: Example 3 57 =3 =3 =2 =2 <=2 Alpha-Beta Pruning: Example 3 58 =3 =3 =2 =2 <=2 <=5 Alpha-Beta Pruning: Example 3 59 =3 =3 =2 =2 <=2 =4 Alpha-Beta Pruning: Example 3 60 =3 =3 =2 =2 <=2 =4 >=4 Alpha-Beta Pruning: Example 3 61 =3 =3 =2 =2 <=2 =4 >=4 prune Alpha-Beta Pruning: Example 3 62 =3 =3 =2 =2 =2 =4 Alpha-Beta Pruning: Example 3 63 =3 =3 =2 =2 =2 =4 >=2 Alpha-Beta Pruning: Example 3 64 =3 =3 =2 =2 =2 =4 >=2 Alpha-Beta Pruning: Example 3 65 =3 =3 =2 =2 =2 =4 <=1 >=2 prune deep cut! Alpha-Beta Pruning: Example 3 66 =3 =3 =2 =2 =2 =4 =1 >=2 <=1 prune <=1 10 nodes explored out of 27 67 Efficiency of Alpha-Beta Pruning ◼ Depends on the order of the siblings ◼ In worst case: ❑ alpha-beta provides no pruning ◼ In best case: ❑ branching factor is reduced to its square root Alpha-Beta: Best ordering 68 Original (arbitrary) game tree Best ordering for alpha-beta Alpha-Beta: Best ordering ◼ best ordering: 1. children of MIN : smallest node first 2. children of MAX: largest node first 69 Alpha-Beta: Best ordering ◼ best ordering: 1. children of MIN : smallest node first 2. children of MAX: largest node first 70 Alpha-Beta: Best ordering 71 ◼ best ordering: 1. children of MIN : smallest node first 2. children of MAX: largest node first Alpha-Beta: Best ordering 72 Alpha-Beta: Best ordering 73 Alpha-Beta: Best ordering 74 8 nodes explored out of 27 75 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic Games ◼ Where we are today Backgammon source: Russel & Norvig (2010) Stochastic (Non-Deterministic) Games ◼ Search tree for games of chance ❑ white can calculate its own legal moves ❑ but it does not know what black will roll... ◼ Idea: add chance nodes to the search tree ❑ branches indicate possible dice rolls ❑ each branch labeled with the roll and its probability (e.g., 1/6 for a single dice roll) Search Tree for Backgammon EXPECTIMINIMAX Algorithm ◼ Calculating EXPECTIMINIMAX ❑ Like MiniMax, but using the weighted sum for Chance nodes: ❑ r is a possible dice roll (or other random event) ❑ P(r) the probability of the event ❑ Result(s, r) is the same state s with dice roll result r ❑ Note: very expensive due to the high branching factor! ❑ See https://en.wikipedia.org/wiki/Expectiminimax for the whole algorithm ෍𝑃 𝑟 𝐸𝑥𝑝𝑒𝑐𝑡𝑖𝑚𝑖𝑛𝑖𝑚𝑎𝑥 𝑅𝑒𝑠𝑢𝑙𝑡 𝑠, 𝑟 https://en.wikipedia.org/wiki/Expectiminimax 84 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic Games ◼ Where we are today 1992-1994 - Checkers: Tinsley vs. Chinook Marion Tinsley World champion for over 40 years In 2007, Schaeffer announced that checkers was solved, and anyone playing against Chinook would only be able to draw, never win. Chinook Developed by Jonathan Schaeffer, professor at the U. of Alberta 1992: Tinsley beat Chinook in 4 games to 2, with 33 draws. 1994: 6 draws VS 85 Play against Chinook: http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo 1997 - Othello: Murakami vs. Logistello Logistello beat Murakami by 6 games to 0 Takeshi Murakami World Othello (aka Reversi) champion VS Logistello developed by Michael Buro runs on a standard PC https://skatgame.net/mburo/log.html (including source code) 86 https://skatgame.net/mburo/log.html 1997- Chess: Kasparov vs. Deep Blue Garry Kasparov 50 billion neurons 2 positions/sec VS Deep Blue 32 RISC processors + 256 VLSI chess engines 200,000,000 pos/sec Deep Blue wins by 3 wins, 1 loss, and 2 draws 87 2003 - Chess: Kasparov vs. Deep Junior Match ends in a 3/3 tie! Garry Kasparov still 50 billion neurons still 2 positions/sec VS Deep Junior 8 CPU, 8 GB RAM, Win 2000 2,000,000 pos/sec Available at $100 88 89 2016 – Go: AlphaGo vs Lee Se-dol ◼ GO was always considered a much harder game to automate than chess because of its very high branching factor (35 for chess vs 250 for Go!) https://www.theverge.com/2016/3/15/11213518/alphago-deepmind-go-match-5-result ◼ In 2016, AlphaGo beat Lee Sedol in a five-game match of GO. ◼ In 2017 AlphaGo beat Ke Jie, the world No.1 ranked player at the time ◼ uses a Monte Carlo tree search algorithm to find its moves based on knowledge previously "learned" by deep learning 90 2017 – AlphaGo Zero & AlphaZero AlphaGo Zero learned the Game by itself, without input of human games ◼ Became better than all old versions after 40 days of training ◼ In the first three days, AlphaGo Zero played 4.9 million games against itself using reinforcement learning AlphaZero can learn other games, like Chess and Shogi ◼ In 2018, it beat the then- best chess program, Stockfish 8 in a 100-game tournament ◼ Trained using 5,000 tensor processing units (TPUs), run on four TPUs and a 44-core CPU during matches 91 2018 – AlphaZero vs Stockfish 8 Game commentary: https://www.youtube.com/watch?v=nPexHaFL1uo https://www.youtube.com/watch?v=nPexHaFL1uo 92 Today ◼ State Space Search for Game Playing ❑ MiniMax ❑ Alpha-beta pruning ❑ Stochastic games ◼ Where we are today